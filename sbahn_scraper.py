import logging
import httpx
from bs4 import BeautifulSoup

async def scrape_sbahn():
    url = "https://sbahn.berlin/fahren/bauen-stoerung/"
    meldungen = []

    async with httpx.AsyncClient(timeout=30) as client:
        r = await client.get(url)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        # Beispiel: alle Cards mit StÃ¶rungsmeldungen
        for item in soup.select("div.card"):
            titel = item.select_one("h3, h2")
            beschreibung = item.select_one("p")
            t = titel.get_text(strip=True) if titel else ""
            b = beschreibung.get_text(" ", strip=True) if beschreibung else ""

            # ðŸ‘‰ Debug-Logging
            logging.info(f"ðŸš† Gefunden: {t} â€“ {b[:100]}")

            meldungen.append({
                "quelle": "S-Bahn",
                "titel": t,
                "beschreibung": b
            })

    logging.info(f"âœ… S-Bahn-Scraper hat {len(meldungen)} Meldungen gefunden.")
    return meldungen
