import subprocess
import os
from fastapi import FastAPI
from scraper import scrape_bvg, scrape_sbahn
from nebenbot import twitter_login_and_tweet
from utils import generate_tweets
from db import is_new_message, save_message, init_db, reset_db_if_monday
import logging
import asyncio

# üîß Playwright-Browser installieren, falls sie fehlen
os.environ["PLAYWRIGHT_BROWSERS_PATH"] = "/tmp/playwright"
try:
    print("üîÑ Playwright-Browser werden installiert...")
    subprocess.run(["playwright", "install"], check=True)
    print("‚úÖ Installation erfolgreich.")
except Exception as e:
    print(f"‚ùå Fehler bei playwright install: {e}")

# Logger Setup
logger = logging.getLogger("bvg-sbahn-bot")
logging.basicConfig(level=logging.INFO)

# Datenbank initialisieren
init_db()
reset_db_if_monday()

app = FastAPI(title="BVG & S-Bahn Bot")

@app.get("/")
def home():
    return {"status": "running"}

@app.get("/update")
async def update():
    logger.info("üîÑ Update gestartet")

    # Asynchrone Scraper ausf√ºhren
    bvg_msgs = await scrape_bvg()
    sbahn_msgs = await scrape_sbahn()

    all_msgs = bvg_msgs + sbahn_msgs
    threads = generate_tweets(all_msgs)

    posted = 0
    for thread in threads:
        # Pr√ºfe nur den ersten Tweet auf Duplikat
        if is_new_message(thread[0]):
            save_message(thread[0])
            await twitter_login_and_tweet(thread)
            posted += 1
        else:
            logger.info("‚è≠Ô∏è Thread bereits bekannt, wird √ºbersprungen.")

    return {"posted": posted, "total_scraped": len(all_msgs)}
